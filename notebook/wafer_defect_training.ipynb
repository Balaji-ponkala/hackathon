{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ZMRsQ_ZhIqk",
        "outputId": "c847c20f-4f86-4a49-c2e4-465c0e3c8c62"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.13), please consider upgrading to the latest version (0.4.2).\n",
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/muhammedjunayed/wm811k-silicon-wafer-map-dataset-image?dataset_version_number=1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 983k/983k [00:00<00:00, 94.7MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n",
            "Path to dataset files: /root/.cache/kagglehub/datasets/muhammedjunayed/wm811k-silicon-wafer-map-dataset-image/versions/1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"muhammedjunayed/wm811k-silicon-wafer-map-dataset-image\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"qingyi/wm811k-wafer-map\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "baIM_F6en6-2",
        "outputId": "0ed3d001-c470-4248-859b-234f84192329"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Colab cache for faster access to the 'wm811k-wafer-map' dataset.\n",
            "Path to dataset files: /kaggle/input/wm811k-wafer-map\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DATASET_PATH = \"/root/.cache/kagglehub/datasets/muhammedjunayed/wm811k-silicon-wafer-map-dataset-image/versions/1/WM811k_Dataset\"\n",
        "\n",
        "import os\n",
        "print(os.listdir(DATASET_PATH))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VbYVxy2XoZaF",
        "outputId": "b8bad0e1-e452-44f8-a58c-8b4b389c6417"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['random', 'none', 'Edge Local', 'Local', 'near full', 'Scratch', 'Center', 'Edge Ring', 'Donut']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "BASE_DIR = \"/content/wafer_dataset\"\n",
        "splits = [\"train\", \"val\", \"test\"]\n",
        "classes = [\"normal\", \"defect\"]\n",
        "\n",
        "for s in splits:\n",
        "    for c in classes:\n",
        "        os.makedirs(os.path.join(BASE_DIR, s, c), exist_ok=True)\n",
        "\n",
        "print(\" Target folder structure created\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T7Hnt496oZjJ",
        "outputId": "52a7290b-2b45-477a-94ac-f9bcc26b152e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Target folder structure created\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import shutil\n",
        "\n",
        "SOURCE_DIR = \"/root/.cache/kagglehub/datasets/muhammedjunayed/wm811k-silicon-wafer-map-dataset-image/versions/1/WM811k_Dataset\"\n",
        "TARGET_DIR = \"/content/wafer_dataset\"\n",
        "\n",
        "TRAIN = 0.7\n",
        "VAL = 0.15\n",
        "\n",
        "def split_copy(files, class_name):\n",
        "    random.shuffle(files)\n",
        "    n = len(files)\n",
        "    t1 = int(n * TRAIN)\n",
        "    t2 = int(n * (TRAIN + VAL))\n",
        "\n",
        "    splits = {\n",
        "        \"train\": files[:t1],\n",
        "        \"val\": files[t1:t2],\n",
        "        \"test\": files[t2:]\n",
        "    }\n",
        "\n",
        "    for split_name, imgs in splits.items():\n",
        "        destination_dir = os.path.join(TARGET_DIR, split_name, class_name)\n",
        "        # The directories should already exist from the previous cell, but this adds robustness\n",
        "        os.makedirs(destination_dir, exist_ok=True)\n",
        "        for img in imgs:\n",
        "            shutil.copy(img, destination_dir)\n",
        "\n",
        "# ---------- NORMAL ----------\n",
        "normal_dir = os.path.join(SOURCE_DIR, \"none\")\n",
        "normal_imgs = [os.path.join(normal_dir, f) for f in os.listdir(normal_dir)]\n",
        "split_copy(normal_imgs, \"normal\")\n",
        "\n",
        "# ---------- DEFECT ----------\n",
        "defect_classes = [d for d in os.listdir(SOURCE_DIR) if d != \"none\"]\n",
        "\n",
        "all_defect_imgs = []\n",
        "for d in defect_classes:\n",
        "    dpath = os.path.join(SOURCE_DIR, d)\n",
        "    all_defect_imgs.extend(\n",
        "        [os.path.join(dpath, f) for f in os.listdir(dpath)]\n",
        "    )\n",
        "\n",
        "split_copy(all_defect_imgs, \"defect\")\n",
        "\n",
        "print(\"Dataset split & merged successfully\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l7nNKYPboZuL",
        "outputId": "c9cc8a1e-827a-46e3-a72f-d5cac764b239"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Dataset split & merged successfully\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for s in [\"train\", \"val\", \"test\"]:\n",
        "    for c in [\"normal\", \"defect\"]:\n",
        "        path = f\"/content/wafer_dataset/{s}/{c}\"\n",
        "        print(s, c, len(os.listdir(path)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5uB5bqyMp2Dt",
        "outputId": "df312478-2de9-4cd9-f6ac-e8148f0c4e75"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train normal 70\n",
            "train defect 561\n",
            "val normal 15\n",
            "val defect 120\n",
            "test normal 15\n",
            "test defect 121\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms, models\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import os\n"
      ],
      "metadata": {
        "id": "Jw0h1koUp2I6"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IMG_SIZE = 224\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(15),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.5], [0.5])\n",
        "])\n",
        "\n",
        "val_test_transform = transforms.Compose([\n",
        "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.5], [0.5])\n",
        "])\n"
      ],
      "metadata": {
        "id": "vEqu-YivqPni"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_DIR = \"/content/wafer_dataset\"\n",
        "\n",
        "train_data = datasets.ImageFolder(os.path.join(DATA_DIR, \"train\"), transform=train_transform)\n",
        "val_data   = datasets.ImageFolder(os.path.join(DATA_DIR, \"val\"), transform=val_test_transform)\n",
        "test_data  = datasets.ImageFolder(os.path.join(DATA_DIR, \"test\"), transform=val_test_transform)\n",
        "\n",
        "train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
        "val_loader   = DataLoader(val_data, batch_size=BATCH_SIZE, shuffle=False)\n",
        "test_loader  = DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "class_names = train_data.classes\n",
        "print(\"Classes:\", class_names)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IyEXANiaqPsP",
        "outputId": "8deca298-0bba-4f2a-9f5a-75f889e5f738"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classes: ['defect', 'normal']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model = models.resnet18(pretrained=True)\n",
        "\n",
        "# Freeze backbone\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Replace classifier\n",
        "model.fc = nn.Sequential(\n",
        "    nn.Linear(model.fc.in_features, 128),\n",
        "    nn.ReLU(),\n",
        "    nn.Dropout(0.4),\n",
        "    nn.Linear(128, 2)\n",
        ")\n",
        "\n",
        "model = model.to(device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "myhFenP7qPxr",
        "outputId": "3f14ff01-5e0c-40ea-878b-4ae051203ee7"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 135MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.fc.parameters(), lr=0.001)\n"
      ],
      "metadata": {
        "id": "VgyClR3FqP4T"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 10\n",
        "\n",
        "best_val_acc = 0\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "\n",
        "    for imgs, labels in train_loader:\n",
        "        imgs, labels = imgs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(imgs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    correct, total = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for imgs, labels in val_loader:\n",
        "            imgs, labels = imgs.to(device), labels.to(device)\n",
        "            outputs = model(imgs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            correct += (preds == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "\n",
        "    val_acc = correct / total\n",
        "    print(f\"Epoch {epoch+1}/{EPOCHS} | Train Loss: {train_loss:.3f} | Val Acc: {val_acc:.3f}\")\n",
        "\n",
        "    if val_acc > best_val_acc:\n",
        "        best_val_acc = val_acc\n",
        "        torch.save(model.state_dict(), \"wafer_defect_model.pth\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XkDmQ_7zqjB9",
        "outputId": "4a54014e-c924-4c5d-dcce-dbf5a3f65f10"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10 | Train Loss: 7.300 | Val Acc: 0.889\n",
            "Epoch 2/10 | Train Loss: 6.158 | Val Acc: 0.889\n",
            "Epoch 3/10 | Train Loss: 5.802 | Val Acc: 0.889\n",
            "Epoch 4/10 | Train Loss: 5.341 | Val Acc: 0.889\n",
            "Epoch 5/10 | Train Loss: 5.076 | Val Acc: 0.896\n",
            "Epoch 6/10 | Train Loss: 4.713 | Val Acc: 0.874\n",
            "Epoch 7/10 | Train Loss: 4.575 | Val Acc: 0.896\n",
            "Epoch 8/10 | Train Loss: 4.303 | Val Acc: 0.904\n",
            "Epoch 9/10 | Train Loss: 3.906 | Val Acc: 0.896\n",
            "Epoch 10/10 | Train Loss: 3.952 | Val Acc: 0.919\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load(\"wafer_defect_model.pth\"))\n",
        "model.eval()\n",
        "\n",
        "correct, total = 0, 0\n",
        "with torch.no_grad():\n",
        "    for imgs, labels in test_loader:\n",
        "        imgs, labels = imgs.to(device), labels.to(device)\n",
        "        outputs = model(imgs)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        correct += (preds == labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "\n",
        "print(\"Test Accuracy:\", correct / total)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sn9EeJsdqjLI",
        "outputId": "5258bea4-4971-46c4-e36f-da6a87127b34"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.8897058823529411\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import numpy as np\n",
        "\n",
        "y_true = []\n",
        "y_pred = []\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for imgs, labels in test_loader:\n",
        "        imgs, labels = imgs.to(device), labels.to(device)\n",
        "        outputs = model(imgs)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "\n",
        "        y_true.extend(labels.cpu().numpy())\n",
        "        y_pred.extend(preds.cpu().numpy())\n",
        "\n",
        "print(confusion_matrix(y_true, y_pred))\n",
        "print(classification_report(y_true, y_pred, target_names=class_names))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ECRgglN6qjZX",
        "outputId": "f3d522f9-f797-4b0d-f470-80c43f478c55"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[120   1]\n",
            " [ 14   1]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      defect       0.90      0.99      0.94       121\n",
            "      normal       0.50      0.07      0.12        15\n",
            "\n",
            "    accuracy                           0.89       136\n",
            "   macro avg       0.70      0.53      0.53       136\n",
            "weighted avg       0.85      0.89      0.85       136\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import models, transforms\n",
        "from PIL import Image\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Class names (VERY IMPORTANT: same order as training)\n",
        "class_names = ['defect', 'normal']\n",
        "\n",
        "# Recreate model architecture\n",
        "model = models.resnet18(pretrained=False)\n",
        "model.fc = nn.Sequential(\n",
        "    nn.Linear(model.fc.in_features, 128),\n",
        "    nn.ReLU(),\n",
        "    nn.Dropout(0.4),\n",
        "    nn.Linear(128, 2)\n",
        ")\n",
        "\n",
        "# Load trained weights\n",
        "model.load_state_dict(torch.load(\"wafer_defect_model.pth\", map_location=device))\n",
        "model = model.to(device)\n",
        "model.eval()\n",
        "\n",
        "print(\"Model loaded successfully\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "39FjYrYVus5X",
        "outputId": "d075af29-1815-490c-be48-bcfca0736015"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded successfully\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.5], [0.5])\n",
        "])\n"
      ],
      "metadata": {
        "id": "bHOCllE8us_C"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_new_image(image_path):\n",
        "    image = Image.open(image_path).convert(\"RGB\")\n",
        "    image = transform(image).unsqueeze(0).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(image)\n",
        "        probs = torch.softmax(outputs, dim=1)\n",
        "        confidence, pred = torch.max(probs, 1)\n",
        "\n",
        "    return class_names[pred.item()], confidence.item()\n"
      ],
      "metadata": {
        "id": "zElopY61u5nQ"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "adhlINQZu5tu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label, confidence = predict_new_image(\"/content/ChatGPT Image Feb 10, 2026, 12_24_02 AM.png\")\n",
        "print(f\"Prediction: {label} | Confidence: {confidence:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "deKHFVu9vUVl",
        "outputId": "048c5f1b-05d4-453a-9dcd-0434c770a2ed"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction: defect | Confidence: 1.00\n"
          ]
        }
      ]
    }
  ]
}